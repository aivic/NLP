{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('jointdf.csv', index_col=0) # Taking only common words between title and content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding words with tags having occurence more than 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bools = ~(df.iloc[:,1].str.contains(r\"'.*': [0-1](,|})?\") & (~(df.iloc[:,1].str.contains(r\"'.*': [^0-1](,|})?\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni = df[bools].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding the maximum value of keys in a new column\n",
    "uni[\"max_val\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni.index = uni.Jword\n",
    "uni = uni.iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalizing the values\n",
    "for i in range(uni.shape[0]):\n",
    "    f = ast.literal_eval(uni.iloc[i,0])\n",
    "    key = list(f.keys())\n",
    "    val = list(f.values())\n",
    "    max_val = max(val)\n",
    "    uni.iloc[i,1] = max_val\n",
    "    try:\n",
    "        val = list(map(lambda x: x/max_val, val))\n",
    "    except:\n",
    "        print(i) # ZeroDivisionError\n",
    "    d = dict(zip(key,val))\n",
    "    uni.iloc[i,0] = uni.iloc[i,0].replace(uni.iloc[i,0],str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a dummy training df \n",
    "content = {\"Few words\":[\"lucky\",\"eating\"],\n",
    "           \"tags\":[[\"Apartments\", \"Buildings\", \"NEWTAG\"],[\"Fog\", \"Sunny\", \"NEWTAG\"]]}\n",
    "dummy = pd.DataFrame(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for h in range(dummy.shape[0]):  \n",
    "    word = dummy.iloc[h,0]              # input word\n",
    "    vals = dummy.iloc[h,1]              # input tags\n",
    "    \n",
    "    # Assuming the word is present in the original look up dictionary\n",
    "    f = ast.literal_eval(uni.loc[word].Tags) # holding look up dictionary\n",
    "    \n",
    "    key = list(f.keys())\n",
    "    val = list(f.values())\n",
    "\n",
    "    classes = []\n",
    "    misclasses = []\n",
    "\n",
    "    # Accounting for right classified and misclassified tags\n",
    "    for i in range(len(vals)):\n",
    "\n",
    "        if vals[i] in key:\n",
    "            classes.append(vals[i])        \n",
    "\n",
    "        else:\n",
    "            misclasses.append(vals[i])       \n",
    "\n",
    "\n",
    "    right_classified = len(classes)\n",
    "    wrong_classified = len(misclasses)\n",
    "\n",
    "    # Updating the weights for rightly classifieds\n",
    "\n",
    "    epsilon = wrong_classified/(right_classified + wrong_classified)\n",
    "\n",
    "    for i in range(right_classified):\n",
    "\n",
    "        # fetching the index of class in orig.\n",
    "        for j in range(len(key)):\n",
    "            if classes[i] == key[j]:\n",
    "                break # tag stored at jth position\n",
    "\n",
    "        # updating the weight\n",
    "        val[j] = (1/(0.5*(1-epsilon))) * val[j]\n",
    "\n",
    "\n",
    "    # Updating the weights for wrongly classifieds\n",
    "    for i in range(wrong_classified):\n",
    "\n",
    "        # fetching the index of class in orig.\n",
    "        flag = 0\n",
    "        for j in range(len(key)):\n",
    "            if misclasses[i] == key[j]:\n",
    "                flag = 1\n",
    "                break # tag stored at jth position\n",
    "\n",
    "        # updating the weight\n",
    "\n",
    "        # CASE 1: TAG is present is original dictionary but not in input dictionary\n",
    "        if flag == 1:\n",
    "            val[j] = (1/(0.5*epsilon)) * val[j]\n",
    "        else:\n",
    "        # CASE 2: A new TAG appears\n",
    "            key.append(misclasses[i])\n",
    "            val.append(1/uni.loc[word].max_val)\n",
    "    \n",
    "    d = dict(zip(key,val))\n",
    "    uni.loc[word,\"Tags\"] = uni.loc[word].Tags.replace(uni.loc[word].Tags,str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a test data and use the word to associate the probabilities (in terms of weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
